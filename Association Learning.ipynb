{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fH0o6ZshUXKB"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.io import imread\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching on GPU\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))\n",
    "# Setting folder\n",
    "folder='data/'\n",
    "print('dataset size: {}'.format(len(os.listdir(folder))))\n",
    "# Looking at classes\n",
    "images=pd.DataFrame(os.listdir(folder), columns=['img_name'])\n",
    "images['label']=images['img_name'].map(lambda x: str(x).split('_')[0])\n",
    "print('samples in dataset:')\n",
    "print(images.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.folder=folder\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(listdir(self.folder))\n",
    "    \n",
    "    def __getitem__(self, index):       \n",
    "        #Create dataframe with name of image, target and it's id\n",
    "        images=pd.DataFrame(os.listdir(self.folder), columns=['img_name'])\n",
    "        images['label']=images['img_name'].map(lambda x: str(x).split('_')[0])\n",
    "        encoder={'pizza':0,'pasta':1,'burger':2,'hotdog':3}\n",
    "        images['target']=images['label'].map(encoder)\n",
    "        images['img_id']=images['img_name'].map(lambda x: str(x).split('.')[0])\n",
    "\n",
    "        #One-hot classes for association\n",
    "        images['italian']=np.where(images['label'].isin(['pizza','pasta']),1,0)\n",
    "        images['american']=np.where(images['label'].isin(['burger','hotdog']),1,0)\n",
    "        images['pizza']=np.where(images['label']=='pizza',1,0)\n",
    "        images['burger']=np.where(images['label']=='burger',1,0)\n",
    "        \n",
    "        multiclass_targets=images[['italian','american','pizza','burger']].as_matrix()\n",
    "        \n",
    "        \n",
    "        img_name=os.path.join(self.folder, images.iloc[index,0])\n",
    "        img=Image.open(img_name)\n",
    "        target=images.iloc[index,2]\n",
    "        img_id=images.iloc[index,1]\n",
    "        multiclass_target=multiclass_targets[index]\n",
    "        #print(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target, multiclass_target, img_id\n",
    "    \n",
    "orig_dataset = FoodDataset(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, indices, count=5):\n",
    "    plt.figure(figsize=(count*3,3))\n",
    "    display_indices = indices[:count]\n",
    "    for i, index in enumerate(display_indices):    \n",
    "        x, y, y_mc, img_id = dataset[index]\n",
    "        plt.subplot(1,count,i+1)\n",
    "        plt.title('label: {}, oh: {}'.format(img_id,y_mc))\n",
    "        plt.imshow(x)\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples and their transformations\n",
    "indices = np.random.choice(np.arange(len(orig_dataset)), 5, replace=False)\n",
    "visualize_samples(orig_dataset, indices)\n",
    "\n",
    "transformed_dataset=FoodDataset(folder, transform=transforms.Compose([\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomRotation((-10,10))\n",
    "                                                                    ]))\n",
    "visualize_samples(transformed_dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SruMYQefUxoA"
   },
   "outputs": [],
   "source": [
    "# Setting dataset\n",
    "dataset=FoodDataset(folder, transform=transforms.Compose([\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomRotation((-10,10)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))                         \n",
    "                                                        ]))\n",
    "\n",
    "# Deviding train dataset into train and validation\n",
    "bs=16\n",
    "#np.random.seed(42)\n",
    "data_size=len(dataset)\n",
    "split=int(np.floor(0.2*data_size))\n",
    "data_indices=list(range(data_size))\n",
    "np.random.shuffle(data_indices)\n",
    "train_indices, val_indices=data_indices[split:], data_indices[:split]\n",
    "train_sampler=SubsetRandomSampler(train_indices)\n",
    "val_sampler=SubsetRandomSampler(val_indices)\n",
    "\n",
    "# DataLoading\n",
    "train_loader=torch.utils.data.DataLoader(dataset, batch_size=bs, sampler=train_sampler)\n",
    "val_loader=torch.utils.data.DataLoader(dataset, batch_size=bs, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uEJkflJgNlu"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epoch=10):\n",
    "    print('Training...')\n",
    "    loss_history=[]\n",
    "    train_history=[]\n",
    "    val_history=[]\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        loss_accum=0\n",
    "        correct_samples=0\n",
    "        total_samples=0\n",
    "        \n",
    "        for i_step, (x,y,y_oh,label) in enumerate(train_loader):\n",
    "            x,y=x.to(device),y.to(device)\n",
    "            prediction=model(x)\n",
    "            loss_value=loss(prediction,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices=torch.max(prediction, 1)\n",
    "            correct_samples+=torch.sum(indices==y)\n",
    "            total_samples+=y.shape[0]\n",
    "            \n",
    "            loss_accum+=loss_value\n",
    "            \n",
    "        scheduler.step()                    \n",
    "        ave_loss=loss_accum/i_step\n",
    "        train_accuracy=float(correct_samples)/total_samples\n",
    "        val_accuracy=compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print('Epoch: {}/{}, Train_loss: {}, Train_accuracy: {}, Val_accuracy: {}'.format(epoch+1,num_epoch,\n",
    "                                                                    ave_loss,train_accuracy,val_accuracy))\n",
    "    return loss_history, train_history, val_history\n",
    "\n",
    "def compute_accuracy(model,loader):\n",
    "    model.eval()\n",
    "    correct_samples=0\n",
    "    total_samples=0\n",
    "    \n",
    "    for i_step, (x,y,y_oh,label) in enumerate(loader):\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        prediction=model(x)\n",
    "        _,indices=torch.max(prediction,1)\n",
    "        correct_samples+=torch.sum(indices==y)\n",
    "        total_samples+=y.shape[0]\n",
    "        \n",
    "    accuracy=float(correct_samples)/total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCDOte0jVQO-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to train 4-class classifier\n",
    "\"\"\"# My model\n",
    "net=models.resnet18(pretrained=True)\n",
    "num_ftrs=net.fc.in_features\n",
    "net.fc=nn.Linear(num_ftrs,4)\n",
    "\n",
    "net.load_state_dict(torch.load('classifier.pt'))\n",
    "net=net.to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters(),lr=1e-3, momentum=0.9)\n",
    "scheduler=StepLR(optimizer,step_size=10, gamma=0.1)\n",
    "\n",
    "loss_history, train_history, val_history = train_model(net, train_loader, val_loader, loss, optimizer, 1)\n",
    "torch.save(net.state_dict(), 'classifier.pt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "k_hUXpUe4rRL",
    "outputId": "74c57949-caa5-4a35-ead7-219d0caaeb26"
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to train 4-class classifier\n",
    "\"\"\"plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_history, label='Train')\n",
    "plt.plot(val_history, label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss_history, label='Train')\n",
    "plt.title('Loss')\n",
    "plt.legend();\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class associator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uEJkflJgNlu"
   },
   "outputs": [],
   "source": [
    "def train_multiclass_model(model, train_loader, val_loader, loss, optimizer, num_epoch):\n",
    "    print('Learning...')\n",
    "    loss_history=[]\n",
    "    accuracy_history=[]\n",
    "    val_accuracy_history=[]\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        loss_accum=0\n",
    "        correct_samples=0\n",
    "        total_samples=0\n",
    "        correct_samples_total=0\n",
    "        total_samples_total=0\n",
    "        \n",
    "        for i_step, (x,y,y_oh,y_class) in enumerate(train_loader):\n",
    "            \n",
    "            y_oh=y_oh.type(torch.FloatTensor)\n",
    "            #Devide classes into cats/cars and dogs/planes: class_one - with 1 ticker - class_two - with 2\n",
    "            y_class=list(y_class)\n",
    "            indexes_one = [i for i,x in enumerate(y_class) if (x == 'pasta')|(x == 'hotdog')] \n",
    "            indexes_two = [i for i,x in enumerate(y_class) if (x == 'burger')|(x == 'pizza')] \n",
    "            \n",
    "            #Calculate loss for 1st part\n",
    "            x_one=x[indexes_one]\n",
    "            y_oh_one=y_oh[indexes_one][:,:2]\n",
    "            x_one, y_oh_one=x_one.to(device), y_oh_one.to(device)      \n",
    "\n",
    "            prediction=model(x_one)\n",
    "            prediction_one=prediction[:,:2]\n",
    "            loss_value_one=loss(prediction_one,y_oh_one)\n",
    "\n",
    "            #Calculate loss for 2nd part\n",
    "            x_two=x[indexes_two]\n",
    "            y_oh_two=y_oh[indexes_two][:,:2]\n",
    "            x_two,y_oh_two=x_two.to(device), y_oh_two.to(device)\n",
    "\n",
    "            prediction_two=model(x_two)[:,:2]\n",
    "            loss_value_two=loss(prediction_two,y_oh_two)\n",
    "\n",
    "            #Calculate total loss\n",
    "            loss_value=(loss_value_one+loss_value_two)/2\n",
    "\n",
    "            #Calculate accuracy of classes 3 and 4 for dogs and planes\n",
    "            prediction_accuracy=prediction[:,2:]\n",
    "            _, indices_pred=torch.max(prediction_accuracy,1)\n",
    "            _, indices_true=torch.max(y_oh_one,1)\n",
    "            correct_samples+=torch.sum(indices_pred==indices_true)\n",
    "            total_samples+=indices_pred.shape[0]\n",
    "\n",
    "            #Calculate accuracy of calsses 1 and 2 for all images\n",
    "            x_total=x\n",
    "            y_total=y_oh[:,:2]\n",
    "            x_total, y_total=x_total.to(device),y_total.to(device)\n",
    "\n",
    "            prediction_total=model(x_total)[:,:2]\n",
    "            _, indices_total_pred=torch.max(prediction_total,1)\n",
    "            _, indices_total_true=torch.max(y_total,1)\n",
    "            correct_samples_total+=torch.sum(indices_total_pred==indices_total_true)\n",
    "            total_samples_total+=indices_total_pred.shape[0]\n",
    "\n",
    "\n",
    "            #Optimize model\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_accum+=loss_value\n",
    "\n",
    "        #scheduler.step()            \n",
    "        ave_loss=loss_accum/i_step\n",
    "        \n",
    "        train_accuracy=float(correct_samples)/total_samples        \n",
    "        class_accuracy_train=float(correct_samples_total)/total_samples_total\n",
    "        val_accuracy=calculate_accuracy(model,val_loader)\n",
    "        \n",
    "        val_accuracy_history.append(val_accuracy)\n",
    "        accuracy_history.append(train_accuracy)\n",
    "        loss_history.append(float(ave_loss))\n",
    "        \n",
    "        print('Epoch: {}/{}, Loss: {}, Acc_train: {}, Acc_val: {}, Acc: {}'.format(epoch+1,\n",
    "                  num_epoch,ave_loss, train_accuracy,val_accuracy,class_accuracy_train))\n",
    "        \n",
    "    return loss_history, accuracy_history, val_accuracy_history\n",
    "\n",
    "def calculate_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct_samples=0\n",
    "    total_samples=0\n",
    "    for i_step, (x,y,y_oh,y_class) in enumerate(loader):\n",
    "        indexes_one = [i for i,x in enumerate(y_class) if (x == 'pasta')|(x == 'hotdog')] \n",
    "        y_oh=y_oh.type(torch.FloatTensor)\n",
    "        y_class=list(y_class)\n",
    "        x,y=x.to(device)[indexes_one],y_oh.to(device)[indexes_one][:,:2]\n",
    "        prediction=model(x)[:,2:]\n",
    "        _, indices_pred=torch.max(prediction,1)\n",
    "        _, indices_true=torch.max(y,1)\n",
    "        correct_samples+=torch.sum(indices_pred==indices_true)\n",
    "        total_samples+=indices_pred.shape[0]\n",
    "    accuracy=float(correct_samples)/total_samples\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCDOte0jVQO-"
   },
   "outputs": [],
   "source": [
    "# My model\n",
    "\n",
    "multiclass_net=models.resnet18(pretrained=True)\n",
    "num_ftrs=multiclass_net.fc.in_features\n",
    "multiclass_net.fc=(nn.Linear(num_ftrs,4))\n",
    "\n",
    "multiclass_net.load_state_dict(torch.load('multiclass.pt'))\n",
    "multiclass_net=multiclass_net.to(device)\n",
    "loss=nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.SGD(multiclass_net.parameters(),lr=1e-3, momentum=0.9)\n",
    "\n",
    "loss_history, accuracy_history, val_accuracy_history = train_multiclass_model(multiclass_net, train_loader, val_loader, loss, optimizer, 1)\n",
    "torch.save(multiclass_net.state_dict(), 'multiclass.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(accuracy_history, label='Train')\n",
    "plt.plot(val_accuracy_history, label='Train')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss_history, label='Train')\n",
    "plt.title('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
